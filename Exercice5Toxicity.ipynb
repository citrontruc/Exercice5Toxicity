{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4\n",
    "\n",
    "---\n",
    "\n",
    "Evaluation de la toxicité de commentaires de pages wikipedia. Cette analyse de fonde sur le jeu de données présent à [cette adresse](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data). Le but de l'exercice est d'identifier dans chacun des commentaires s'il est toxique et la raison pour laquelle il a été identifié comme étant toxique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1) Vérification de la qualité des données\n",
    "\n",
    "---\n",
    "\n",
    "Vérifiez la qualité des données (nombre lignes et colonnes, valeurs vides, etc...). Dans quelles langues sont les commentaires ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2) Analyse des textes.\n",
    "\n",
    "1) Analysez la distribution des différents types de toxicité. Quels sont les plus nombreux et lesquels les moins nombreux ?\n",
    "1) Analysez la distribution des longueurs de textes. Quels sont les commentaires les plus longs ?\n",
    "3) Ajoutez une colonne de booléens qui indique si le message contient des mots intégralement en majuscules. (On éliminera les mots de moins de 3 lettres).\n",
    "4) Ajoutez une colonne qui indique si le message contient des mots vulgaires. (Utiliser la bibliothèque alt-profanity-check, predict et predict_proba sont des méthodes valables). Est-ce que cette colonne est pertinente ?\n",
    "1) Quelle est la corrélation entre les différentes catégories ? Cela vous semble-t-il normal ?\n",
    "2) Est-ce que les catégories toxic et severe_toxic sont mutuellement exclusives ? Est-ce qu'il est possible qu'une catégorie soit marquée comme étant severe_toxic, obscene, threat, insult ou identity_hate sans être marquée comme étant toxic ?\n",
    "3) Faites du stemming pour regrouper les termes de même familles\n",
    "5) Quels sont les mots clés les plus associés à chaque catégorie de toxicité ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3) Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "1) A partir de la partie précédente, vous semble-t-il pertinent de créer un modèle pour chacune des différentes catégories de toxicité ? \n",
    "2) Au vue de la distribution des différentes catégories, comment faire en sorte que les valeurs rares soient mieux représentées ?\n",
    "2) Créez un modèle TF-IDF avec un tf-idf-vectorizer. Est-ce que cette approche semble pertinente ? Proposez une alternative.\n",
    "3) Créez un modèle de machine learning approprié pour chacune des catégories de toxicité (les modèles de ML classique ne prédisent qu'une seule sortie).\n",
    "2) Evaluez les résultats du modèle.\n",
    "2) Faites un embedding du texte.\n",
    "3) Construisez un modèle de Deep Learning pour prédire les types de toxicité.\n",
    "4) Evaluez les résultats pour chacunes des catégories.\n",
    "5) Conclure sur les performances de votre modèle.\n",
    "\n",
    "---\n",
    "\n",
    "Note : tensorflow et pytorch sont les deux bibliohtèques utilisées pour le deep learning. Au delà d'une syntaxe différente, les bibliothèques ne font rien de particulièrement dfférent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
